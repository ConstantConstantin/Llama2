<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Developer&#39;s Corner · Llama2.jl</title><meta name="title" content="Developer&#39;s Corner · Llama2.jl"/><meta property="og:title" content="Developer&#39;s Corner · Llama2.jl"/><meta property="twitter:title" content="Developer&#39;s Corner · Llama2.jl"/><meta name="description" content="Documentation for Llama2.jl."/><meta property="og:description" content="Documentation for Llama2.jl."/><meta property="twitter:description" content="Documentation for Llama2.jl."/><meta property="og:url" content="https://ConstantConstantin.github.io/Llama2.jl/devs/"/><meta property="twitter:url" content="https://ConstantConstantin.github.io/Llama2.jl/devs/"/><link rel="canonical" href="https://ConstantConstantin.github.io/Llama2.jl/devs/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Llama2.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../inference/">Inference</a></li><li class="is-active"><a class="tocitem" href>Developer&#39;s Corner</a><ul class="internal"><li><a class="tocitem" href="#Tokenizer"><span>Tokenizer</span></a></li><li><a class="tocitem" href="#Transformer"><span>Transformer</span></a></li><li><a class="tocitem" href="#forward!"><span>forward!</span></a></li><li><a class="tocitem" href="#Sampler"><span>Sampler</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Developer&#39;s Corner</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Developer&#39;s Corner</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ConstantConstantin/Llama2.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ConstantConstantin/Llama2.jl/blob/main/docs/src/devs.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Developer&#39;s-Corner"><a class="docs-heading-anchor" href="#Developer&#39;s-Corner">Developer&#39;s Corner</a><a id="Developer&#39;s-Corner-1"></a><a class="docs-heading-anchor-permalink" href="#Developer&#39;s-Corner" title="Permalink"></a></h1><p>You want to understand how this package works or modify the code you are running? Here the necessary tools are provided and explained.</p><h2 id="Tokenizer"><a class="docs-heading-anchor" href="#Tokenizer">Tokenizer</a><a id="Tokenizer-1"></a><a class="docs-heading-anchor-permalink" href="#Tokenizer" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Llama2.Tokenizer"><a class="docstring-binding" href="#Llama2.Tokenizer"><code>Llama2.Tokenizer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Tokenizer</code></pre><p>Construct a tokenizer storing vocabulary entries, scores, and byte-piece mappings.</p><p><strong>Constructors</strong></p><ul><li><p><code>Tokenizer(vocab, vocab_scores, sorted_vocab, vocab_size, max_token_length, byte_pieces)</code>   Construct a tokenizer directly from the provided fields.   Validate that <code>max_token_length &gt; 0</code> and that <code>byte_pieces</code> has length 256.</p></li><li><p><code>Tokenizer(path::String, vocab_size::Integer)</code>   Load a tokenizer from a binary file.</p></li></ul><p><strong>Fields</strong></p><ul><li><code>vocab</code>: Token string sequences.  </li><li><code>vocab_scores</code>: Scores for each token.  </li><li><code>sorted_vocab</code>: Sorted token indices.  </li><li><code>vocab_size</code>: Number of vocabulary entries.  </li><li><code>max_token_length</code>: Maximum token length in bytes.  </li><li><code>byte_pieces</code>: Byte mapping (length 256).</li></ul><hr/><pre><code class="language-julia hljs">Tokenizer(path::String, vocab_size::Integer) -&gt; Tokenizer</code></pre><p>Load a tokenizer from a binary file.</p><p>Read vocabulary, token scores, and metadata from the binary file at <code>path</code>. The file format expects:</p><ul><li>Int32: maximum token length</li><li>For each of <code>vocab_size</code> tokens:<ul><li>Float32: token score</li><li>Int32: string length (n)</li><li>n bytes: token string (UTF-8)</li></ul></li></ul><p><strong>Arguments</strong></p><ul><li><code>path::String</code>: Path to the tokenizer binary file.</li><li><code>vocab_size::Integer</code>: Expected number of vocabulary entries.</li></ul><p><strong>Returns</strong></p><ul><li><code>Tokenizer</code>: A tokenizer ready for encoding/decoding text.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/tokenizer.jl#L59-L99">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.TokenIndex"><a class="docstring-binding" href="#Llama2.TokenIndex"><code>Llama2.TokenIndex</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TokenIndex(str::String, id::Integer)</code></pre><p>A vocabulary token with its string representation and numeric identifier.</p><p>Stores a token string and its associated ID for efficient sorting and lookup in the tokenizer vocabulary.</p><p>Throw a <code>DomainError</code> if <code>id ≤ 0</code>.</p><p><strong>Arguments</strong></p><ul><li><code>str::String</code>: Token string (e.g., &quot;Julia&quot;).</li><li><code>id::Integer</code>: Token identifier (converted to <code>Int16</code>, must be ≥ 0).</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; Llama2.TokenIndex(&quot;Julia&quot;, 1)
Llama2.TokenIndex(&quot;Julia&quot;, 1)

julia&gt; Llama2.TokenIndex(&quot;Julia&quot;, -1)
ERROR: DomainError with Token index must be &gt; 0.
[...]</code></pre><p><strong>Developer Notes</strong></p><p>This is an internal struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/tokenizer.jl#L1-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Base.isless-Tuple{Llama2.TokenIndex, Llama2.TokenIndex}"><a class="docstring-binding" href="#Base.isless-Tuple{Llama2.TokenIndex, Llama2.TokenIndex}"><code>Base.isless</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">Base.isless(first_token::TokenIndex, second_token::TokenIndex) -&gt; Bool</code></pre><p>Compare two tokens lexicographically by their string values.</p><p>Return <code>true</code> if <code>first_token.str &lt; second_token.str</code> in lexicographic order. Intended for use as the <code>lt</code> argument to sorting functions.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; isless(Llama2.TokenIndex(&quot;A&quot;, 1), Llama2.TokenIndex(&quot;B&quot;, 2))
true

julia&gt; isless(Llama2.TokenIndex(&quot;B&quot;, 1), Llama2.TokenIndex(&quot;A&quot;, 2))
false</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/tokenizer.jl#L40-L56">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.str_lookup"><a class="docstring-binding" href="#Llama2.str_lookup"><code>Llama2.str_lookup</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">str_lookup(str::String, sorted_vocab::Vector{TokenIndex}) -&gt; Int16</code></pre><p>Search for <code>str</code> within a sorted vocabulary <code>sorted_vocab</code>. If a match is found, it returns the corresponding token ID; <strong>otherwise, it returns <code>-1</code>.</strong> It uses a binary search for efficient lookup.</p><p><strong>Arguments</strong></p><ul><li><code>str::String</code>: Token string to search for.</li><li><code>sorted_vocab::Vector{TokenIndex}</code>: Vocabulary sorted lexicographically by string.</li></ul><p><strong>Returns</strong></p><ul><li><code>Int16</code>: Token ID if found, <code>-1</code> otherwise.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; Llama2.str_lookup(&quot;aa&quot;, [Llama2.TokenIndex(&quot;aa&quot;, 1), Llama2.TokenIndex(&quot;bb&quot;, 2)])
1

julia&gt; Llama2.str_lookup(&quot;ba&quot;, [Llama2.TokenIndex(&quot;aa&quot;, 1), Llama2.TokenIndex(&quot;bb&quot;, 2)])
-1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/tokenizer.jl#L150-L172">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.encode"><a class="docstring-binding" href="#Llama2.encode"><code>Llama2.encode</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">encode(tokenizer::Tokenizer, text::String) -&gt; Vector{Integer}</code></pre><p>Converts <code>text</code> into a sequence of token IDs using <code>tokenizer</code>. First ensure the tokenizer&#39;s vocabulary is sorted, then encode each character into its corresponding ID. After that, iteratively merge token pairs with the highest scores to form longer tokens until no more merges are possible. Return the final token ID sequence.</p><p><strong>Arguments</strong></p><ul><li><code>tokenizer::Tokenizer</code>: The tokenizer with vocabulary and merge scores.</li><li><code>text::String</code>: Input text to encode.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Integer}</code>: Sequence of token IDs representing the encoded text.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/tokenizer.jl#L184-L199">source</a></section></details></article><h2 id="Transformer"><a class="docs-heading-anchor" href="#Transformer">Transformer</a><a id="Transformer-1"></a><a class="docs-heading-anchor-permalink" href="#Transformer" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Llama2.Transformer"><a class="docstring-binding" href="#Llama2.Transformer"><code>Llama2.Transformer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Transformer(config::Config, weights::TransformerWeights)</code></pre><p>Create a <code>Transformer</code> with data from <code>config</code> and <code>weights</code>. The <code>RunState</code> containers are initialized empty and just are assigned the corresponding dimensions.</p><p><strong>Developer Notes</strong></p><p>This is an internal struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/structs.jl#L58-L65">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.Config"><a class="docstring-binding" href="#Llama2.Config"><code>Llama2.Config</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Config</code></pre><p>Create a <code>Config</code> containing 7 <code>Int32</code>. These describe meta-data to read values from an input file.</p><p><strong>Developer Notes</strong></p><p>This is an internal struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/structs.jl#L3-L10">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.TransformerWeights"><a class="docstring-binding" href="#Llama2.TransformerWeights"><code>Llama2.TransformerWeights</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TransformerWeights</code></pre><p>Create a <code>TransformerWeights</code> containing several <code>Float32</code> containers. These describe actual weight data that is loaded from an input file.</p><p><strong>Developer Notes</strong></p><p>This is an internal struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/structs.jl#L21-L28">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.RunState"><a class="docstring-binding" href="#Llama2.RunState"><code>Llama2.RunState</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">RunState</code></pre><p>Create a <code>RunState</code> containing several <code>Float32</code> containers. These reflect the state of the <code>Transformer</code> at run-time.</p><p><strong>Developer Notes</strong></p><p>This is an internal struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/structs.jl#L44-L51">source</a></section></details></article><h2 id="forward!"><a class="docs-heading-anchor" href="#forward!">forward!</a><a id="forward!-1"></a><a class="docs-heading-anchor-permalink" href="#forward!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Llama2.forward!"><a class="docstring-binding" href="#Llama2.forward!"><code>Llama2.forward!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">forward!(transformer::Transformer, token::Int32, pos::Int32)</code></pre><p>Perform a single forward pass through the transformer.</p><p>Compute logits for the next token prediction given the current <code>token</code> at position <code>pos</code> in the sequence. Updates the internal KV-cache in <code>transformer.state</code> with keys and values from this forward pass.</p><p><strong>Arguments</strong></p><ul><li><code>transformer::Transformer</code>: The model (modified in-place via KV-cache updates).</li><li><code>token::Int32</code>: Current input token index (must be in range <code>1:vocab_size</code>).</li><li><code>pos::Int32</code>: Position in the sequence (1-indexed, must be ≤ <code>seq_len</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Float32}</code>: Logits over the vocabulary for next token prediction (length = <code>vocab_size</code>).</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">model = Transformer(&quot;model.bin&quot;)
token = Int32(1)  # BOS token
pos = Int32(1)

logits = forward!(model, token, pos)
next_token = argmax(logits)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/forward.jl#L85-L111">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.rmsnorm"><a class="docstring-binding" href="#Llama2.rmsnorm"><code>Llama2.rmsnorm</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rmsnorm(x, w) -&gt; Vector{Float32}</code></pre><p>Calculate the rmsnorm of <code>x</code> and <code>w</code>, the scaled product &#39;λw * x&#39;.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractVector{Float32}</code>: Input vector to normalize.</li><li><code>w::AbstractVector{Float32}</code>: Scale weights (must have same length as <code>x</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Float32}</code>: Normalized and scaled output.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt;  x = [1.0f0,2,3];

julia&gt;  w = [1.0f0,1,1];

julia&gt; o = Llama2.rmsnorm(x, w) 
3-element Vector{Float32}:
 0.46290955
 0.9258191
 1.3887286</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/forward.jl#L1-L25">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.softmax!"><a class="docstring-binding" href="#Llama2.softmax!"><code>Llama2.softmax!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">softmax!(x) -&gt; Vector{Float32}</code></pre><p>Updates the output of an layer &#39;x&#39; with the softmax! of the input.</p><p>Transform logits into a probability distribution by exponentiating and normalizing. Uses the numerically stable formulation: <code>x[i] = exp(x[i] - max(x)) / sum(exp(x .- max(x)))</code>.</p><p>The input vector is modified in-place and also returned.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractVector{Float32}</code>: Logits to transform (modified in-place).</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Float32}</code>: The same vector <code>x</code>, now containing probabilities that sum to 1.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; x = [-1.0f0,0,1];

julia&gt; Llama2.softmax!(x);

julia&gt; x
3-element Vector{Float32}:
 0.09003057
 0.24472848
 0.66524094</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/forward.jl#L41-L69">source</a></section></details></article><h2 id="Sampler"><a class="docs-heading-anchor" href="#Sampler">Sampler</a><a id="Sampler-1"></a><a class="docs-heading-anchor-permalink" href="#Sampler" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Llama2.Sampler"><a class="docstring-binding" href="#Llama2.Sampler"><code>Llama2.Sampler</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Sampler</code></pre><p>Stateful sampler for converting model logits into token indices.</p><p>Encapsulate sampling configuration (temperature, nucleus sampling) and internal buffers needed for efficient token sampling.</p><p><strong>Constructors</strong></p><ul><li><p><code>Sampler(vocab_size::Int32, temperature::Float32, topp::Float32, rng_seed::Int128)</code>   Construct a sampler with automatically allocated internal buffers for nucleus (top-p) sampling.</p></li><li><p><code>Sampler(vocab_size::Int32, probindex::Vector{ProbIndex},           temperature::Float32, topp::Float32, rng_state::Int128)</code>   Construct a sampler using a caller-provided <code>probindex</code> workspace buffer. The buffer must have length at least <code>vocab_size</code>.</p></li></ul><p><strong>Fields</strong></p><ul><li><code>vocab_size::Int32</code>: Vocabulary size</li><li><code>temperature::Float32</code>: Sampling temperature (0 = greedy)</li><li><code>topp::Float32</code>: Nucleus sampling threshold</li><li><code>rng_state::Int128</code>: Random number generator state</li></ul><p><code>Sampler</code> is <em>callable</em> and can be applied to a vector of logits to obtain the next token index.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/sampler.jl#L31-L57">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.ProbIndex"><a class="docstring-binding" href="#Llama2.ProbIndex"><code>Llama2.ProbIndex</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ProbIndex</code></pre><p>Create a <code>ProbIndex</code> from an <code>AbstractFloat</code> and an <code>Integer</code>.</p><p><code>prob</code> contains a proberbility and is stored as an <code>Int32</code> and <code>index</code> is stored as a <code>Float32</code>. Throw a <code>DomainError</code> if <code>index &lt; 0</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; Llama2.ProbIndex(1.0, 2)
ProbIndex(1.0f0, 2)

julia&gt; ProbIndex(1.0, -1)
ERROR: DomainError with Prob index must be &gt; 0.:
[...]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/sampler.jl#L1-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Base.isless-Tuple{Llama2.ProbIndex, Llama2.ProbIndex}"><a class="docstring-binding" href="#Base.isless-Tuple{Llama2.ProbIndex, Llama2.ProbIndex}"><code>Base.isless</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">isless(a::ProbIndex, b::ProbIndex) -&gt; Bool</code></pre><p>Comparison function for ordering <code>ProbIndex</code> values by probability.</p><p>Return <code>true</code> if <code>a.prob &lt; b.prob</code>. Intended for use as the <code>lt</code> argument to sorting routines.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/sampler.jl#L117-L124">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.sample_mult"><a class="docstring-binding" href="#Llama2.sample_mult"><code>Llama2.sample_mult</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sample_mult(probabilities, coin) -&gt; Int</code></pre><p>Sample an index from a multinomial distribution.</p><p>Given a vector of normalized probabilities and a uniform random number <code>coin ∈ [0, 1)</code>, returns the first index whose cumulative probability exceeds <code>coin</code>.</p><p><strong>Arguments</strong></p><ul><li><code>probabilities::Vector{Float32}</code>: Probability mass function (must sum to 1).</li><li><code>coin::Float32</code>: Uniform random number in <code>[0, 1)</code>.</li></ul><p><strong>Returns</strong></p><ul><li>Index of the sampled element.</li></ul><p>If numerical roundoff prevents an early return, the last index is returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/sampler.jl#L86-L103">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Llama2.sample_topp"><a class="docstring-binding" href="#Llama2.sample_topp"><code>Llama2.sample_topp</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sample_topp(probabilities, topp, probindex, coin) -&gt; Int</code></pre><p>Sample an index using nucleus (top-p) sampling.</p><p>Selects the smallest set of tokens whose cumulative probability mass exceeds <code>topp</code>, then samples from this restricted distribution using the provided random number.</p><p><strong>Arguments</strong></p><ul><li><code>probabilities::Vector{Float32}</code>: Normalized probability distribution.</li><li><code>topp::Float32</code>: Cumulative probability threshold (<code>0 &lt; topp &lt; 1</code>).</li><li><code>probindex::Vector{ProbIndex}</code>: Preallocated workspace for sorting and indexing candidate tokens.</li><li><code>coin::Float32</code>: Uniform random number in <code>[0, 1)</code>.</li></ul><p><strong>Returns</strong></p><ul><li>Index of the sampled token.</li></ul><p>The <code>probindex</code> buffer is mutated and reused to avoid allocations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ConstantConstantin/Llama2.jl/blob/9de3120593b0555e453a94aa7ecf2765cf71c1d6/src/sampler.jl#L127-L147">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../inference/">« Inference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 30 January 2026 22:49">Friday 30 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
